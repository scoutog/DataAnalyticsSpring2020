rape.lm.fit <- lm(Rape.Rate ~ ., data=rates)
summary(rape.lm.fit)
# Model assessment VIO
modelSummary <- summary(vio.lm.fit)  # capture model summary as an object
#Model
vio.lm.fit <- lm(Violent.Crime.rate ~., data=rates)
summary(vio.lm.fit)
rape.lm.fit <- lm(Rape.Rate ~ ., data=rates)
summary(rape.lm.fit)
# Model assessment VIO
modelSummary <- summary(vio.lm.fit)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["speed", "Estimate"]  # get beta estimate for speed
std.error <- modelCoeffs["speed", "Std. Error"]  # get std.error for speed
t_value <- beta.estimate/std.error  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(cars)-ncol(cars))  # calc p Value
f_statistic <- linearMod$fstatistic[1]  # fstatistic
# Model assessment VIO
modelSummary <- summary(rape.lm.fit)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["speed", "Estimate"]  # get beta estimate for speed
summary(rape.lm.fit)
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["Rape.Rate", "Estimate"]  # get beta estimate for speed
# Model assessment VIO
modelSummary <- summary(rape.lm.fit)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["Rape.Rate", "Estimate"]  # get beta estimate for speed
beta.estimate <- modelCoeffs["Year", "Estimate"]  # get beta estimate for speed
std.error <- modelCoeffs["Year", "Std. Error"]  # get std.error for speed
t_value <- beta.estimate/std.error  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(rates)-ncol(rates))  # calc p Value
f_statistic <- linearMod$fstatistic[1]  # fstatistic
f_statistic <- rape.lm.fit$fstatistic[1]  # fstatistic
f <- summary(rape.lm.fit)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
t_value
p_value
f_statistic
model_p
AIC(rape.lm.fit)
BIC(rape.lm.fit)
# Model assessment
model <- rape.lm.fit
modelSummary <- summary(model)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["Year", "Estimate"]  # get beta estimate for speed
std.error <- modelCoeffs["Year", "Std. Error"]  # get std.error for speed
t_value <- beta.estimate/std.error  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(rates)-ncol(rates))  # calc p Value
f_statistic <- model$fstatistic[1]  # fstatistic
f <- summary(model)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
t_value # larger t value is better
p_value # low is better
f_statistic
model_p
AIC(model)
BIC(model)
model <- vio.lm.fit
modelSummary <- summary(model)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["Year", "Estimate"]  # get beta estimate for speed
std.error <- modelCoeffs["Year", "Std. Error"]  # get std.error for speed
t_value <- beta.estimate/std.error  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(rates)-ncol(rates))  # calc p Value
f_statistic <- model$fstatistic[1]  # fstatistic
f <- summary(model)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
t_value # larger t value is better
p_value # low is better
f_statistic
model_p
AIC(model)
BIC(model)
model <- vio.lm.fit
modelSummary <- summary(model)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["Rape.Rate", "Estimate"]  # get beta estimate for speed
std.error <- modelCoeffs["Rape.Rate", "Std. Error"]  # get std.error for speed
t_value <- beta.estimate/std.error  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(rates)-ncol(rates))  # calc p Value
f_statistic <- model$fstatistic[1]  # fstatistic
f <- summary(model)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
t_value # larger t value is better
p_value # low is better
f_statistic
model_p
AIC(model)
BIC(model)
summary(rape.lm.fit)
# Prediction models
set.seed(100)
trainingRowIndex <- sample(1:nrow(rates), 0.8*nrow(rates))
trainingData <- rates[trainingRowIndex, ]
testData  <- rates[-trainingRowIndex, ]
# Prediction models
set.seed(100)
trainingRowIndex <- sample(1:nrow(rates), 0.8*nrow(rates))
train <- rates[trainingRowIndex, ]
test  <- rates[-trainingRowIndex, ]
vio.mod <- lm(Violent.Crime.rate ~., train)
vio.pred <- predict(vio.mod, test)
summary(vio.mod)
AIC(vio.mod)
actuals_preds <- data.frame(cbind(actuals=test$Violent.Crime.rate, predicteds=vio.pred))
correlation_accuracy <- cor(actuals_preds)  # 82.7%
head(actuals_preds)
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))
min_max_accuracy
# => 74.86%, min_max accuracy
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape
# => 74.86%, min_max accuracy
actuals_preds
# => 74.86%, min_max accuracy
actuals_preds[3.1]
# => 74.86%, min_max accuracy
actuals_preds[3,1]
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 0.00001
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 1
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape
cvResults <- suppressWarnings(CVlm(df=rates,
form.lm=Violent.Crime.rate ~ ., m=5,
dots=FALSE, seed=29,
legend.pos="topleft",
printit=FALSE,
main="Small symbols are predicted values while bigger ones are actuals."));
library(DAAG)
install.packages("DAAG")
library(DAAG)
cvResults <- suppressWarnings(CVlm(df=rates,
form.lm=Violent.Crime.rate ~ ., m=5,
dots=FALSE, seed=29,
legend.pos="topleft",
printit=FALSE,
main="Small symbols are predicted values while bigger ones are actuals."));
cvResults <- suppressWarnings(CVlm(df=rates,
form.lm=Violent.Crime.rate ~ ., m=5,
dots=FALSE, seed=29,
legend.pos="topleft",
printit=FALSE,
main="Small symbols are predicted values while bigger ones are actuals."));
attr(cvResults, 'ms')  # => 251.2783 mean squared error
cvResults <- CVlm(df=rates, form.lm=Violent.Crime.rate ~ ., m=5, dots=FALSE, seed=29, legend.pos="topleft", printit=FALSE,main="Small symbols are predicted values while bigger ones are actuals."))
cvResults <- CVlm(df=rates, form.lm=Violent.Crime.rate ~ ., m=5, dots=FALSE, seed=29, legend.pos="topleft", printit=FALSE,main="Small symbols are predicted values while bigger ones are actuals.")
cvResults <- CVlm(data=rates, form.lm=Violent.Crime.rate ~ ., m=5, dots=FALSE, seed=29, legend.pos="topleft", printit=FALSE,main="Small symbols are predicted values while bigger ones are actuals.")
attr(cvResults, 'ms')  # => 251.2783 mean squared error
rape.mod <- lm(Rape.rate ~., train)
set.seed(100)
trainingRowIndex <- sample(1:nrow(rates), 0.8*nrow(rates))
train <- rates[trainingRowIndex, ]
test  <- rates[-trainingRowIndex, ]
rape.mod <- lm(Rape.rate ~., train)
View(train)
rape.mod <- lm(Rape.Rate ~., train)
rape.pred <- predict(rape.mod, test)
summary(rape.mod)
AIC(rape.mod)
actuals_preds <- data.frame(cbind(actuals=test$Rape.Rate, predicteds=rape.pred))
correlation_accuracy <- cor(actuals_preds)  # 82.7%
head(actuals_preds)
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))
min_max_accuracy
# => 92.11%, min_max accuracy
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 23.47%
set.seed(100)
trainingRowIndex <- sample(1:nrow(rates), 0.8*nrow(rates))
train <- rates[trainingRowIndex, ]
test  <- rates[-trainingRowIndex, ]
vio.mod <- lm(Violent.Crime.rate ~., train)
vio.pred <- predict(vio.mod, test)
summary(vio.mod)
AIC(vio.mod)
actuals_preds <- data.frame(cbind(actuals=test$Violent.Crime.rate, predicteds=vio.pred))
correlation_accuracy <- cor(actuals_preds)  # 82.7%
head(actuals_preds)
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))
min_max_accuracy
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 1
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 23.47%
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 0.5
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 23.47%
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 0.1
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 23.47%
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 0.01
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 23.47%
# => 74.86%, min_max accuracy
actuals_preds[3,1] <- 0.1
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 23.47%
rape.mod <- lm(Rape.Rate ~., train)
rape.pred <- predict(rape.mod, test)
summary(rape.mod)
AIC(rape.mod)
actuals_preds <- data.frame(cbind(actuals=test$Rape.Rate, predicteds=rape.pred))
correlation_accuracy <- cor(actuals_preds)  # 82.7%
head(actuals_preds)
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))
min_max_accuracy
# => 92.11%, min_max accuracy
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 0.079%
library(BBmisc)
##################################################
df <- read.csv("fbi_crimes.csv", nrows = 20)
df <- df[,1:20]
colnames(df)[colnames(df) == 'Ã¯..Year'] <- 'Year'
summary(df)
sapply(df, class)
cols.num <- c(2,3,5,7,9,11,13,15,17,19,14,18)
df[,cols.num] <- sapply(df[cols.num],as.numeric)
sapply(df, class)
all <- c(2:20)
rescale <- function(x) (x-min(x))/(max(x) - min(x)) * 100
df[,all] <- sapply(df[all], rescale)
summary(df)
##################################################
library(tidyverse)
ggplot(data=df, aes(Year, Population)) +
geom_point() + geom_line()
library(ggplot2)
library(reshape2)
d <- melt(df, id.vars="Year")
ggplot(d, aes(Year,value, col=variable)) +
geom_point() + geom_line()
#  + stat_smooth()
# Separate plots
ggplot(d, aes(Year,value, col=variable)) +
geom_point(show.legend = FALSE) +
stat_smooth(show.legend = FALSE) +
facet_wrap(~variable)
##################################################
rate <- c(1,2,4,6,8,10,12,14,16,18,20)
rates <- df[,rate]
number <- c(1,2,3,5,7,9,11,13,15,17,19)
numbers <- df[,number]
d_rates <- melt(rates, id.vars="Year")
ggplot(d_rates, aes(Year,value, col=variable)) +
geom_point() + geom_line() #+
#  stat_smooth()
# Separate plots
ggplot(d_rates, aes(Year,value, col=variable)) +
geom_point(show.legend = FALSE) +
stat_smooth(show.legend = FALSE) +
facet_wrap(~variable)
d_nums <- melt(numbers, id.vars="Year")
ggplot(d_nums, aes(Year,value, col=variable)) +
geom_point() + geom_line()
#  + stat_smooth()
# Separate plots
ggplot(d_nums, aes(Year,value, col=variable)) +
geom_point(show.legend = FALSE) +
stat_smooth(show.legend = FALSE) +
facet_wrap(~variable)
### CORRELATION
rates2 <- rates
colnames(rates2) <- c("Year","Pop","Violent","Murder","Rape","Robbery","AggAss","Prop","Burg","Larceny","Vehicle")
res <- cor(rates2)
round(res, 2)
library("Hmisc")
res2<-rcorr(as.matrix(rates2[,2:11]))
library(corrplot)
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
corrplot(res2$r, type="upper", order="hclust",
p.mat = res2$P, sig.level = 0.01, insig = "blank")
# Insignificant correlations are leaved blank
corrplot(res2$r, type="upper", order="hclust",
p.mat = res2$P, sig.level = 0.01, insig = "blank")
xyz <- cor(rates2[,2:11])
corrplot.mixed(xyz, lower.col = "black", number.cex = .9)
corrplot(xyz, order="hclust", addrect=3, col = cm.colors(100))
corrplot(xyz, type = "lower", order = "hclust", tl.col = "black", tl.srt = 45)
#####################################
####### Time Series Analysis ########
#####################################
library(forecast)
violent.ts <- ts(rates$Violent.Crime.rate,start = c(1997),end = c(2016),freq=1)
nValid <- 12
violent_train <- window(violent.ts, start = c(1997), end = c(2010))
violent_valid <- window(violent.ts, start = c(2010), end = c(2016))
plot(violent_train,xlab="Time",ylab="Violent Crime Rate",ylim=c(min(rates$Violent.Crime.rate), max(rates$Violent.Crime.rate)),bty="l")
## B
train.lm.season <- tslm(violent_train ~ trend, lambda=0)
# train.lm.season <- tslm(violent_train ~ trend, lambda = 0)
train.lm.season.pred <- forecast(train.lm.season, h=6, level=0)
print(summary(train.lm.season))
plot(train.lm.season.pred,  ylab = "Violent Crime Rate", ,bty='l',xlab = "Time",xaxt="n", ylim=c(min(rates$Violent.Crime.rate), max(rates$Violent.Crime.rate)),xlim = c(1997,2016), main = "", flty = 2, col="red")
axis(1, at = seq(1997, 2016, 1))
lines(violent_train)
lines(train.lm.season$fitted, lwd = 2, col="blue")
lines(violent_valid)
grid()
lines(c(2010, 2010), c(min(rates$Violent.Crime.rate), max(rates$Violent.Crime.rate)),lwd=3,col="red")
text(1998, 30000000, "Training",cex=1)
text(2002, 40000000, "Validation",cex=1)
text(1992, 65000000, "Air", cex=1.5)
accuracy(train.lm.season$fitted, violent_valid)
library(TTR)
sma_vio <- SMA(violent.ts,n=1)
plot.ts(sma_vio)
vio_fore <- HoltWinters(violent.ts, gamma=F)
plot(vio_fore)
####################################
####### Regression Analysis ########
####################################
scatter.smooth(x=rates$Year, y=rates$Violent.Crime.rate, main = "Year ~ Violent Crime Rate")
scatter.smooth(x=rates$Year, y=rates$Rape.Rate, main = "Year ~ Rape Rate")
#Box plot for outlier
par(mfrow=c(1,2))
boxplot(rates$Violent.Crime.rate, main="Violent Crime Rate")
# , sub=paste("Outlier Rows: ", boxplot.stats(rates$Violent.Crime.rate)$out))
boxplot(rates$Rape.Rate, main="Rape Rate")
# Check density plot
library(e1071)
par(mfrow=c(1, 2))  # divide graph area in 2 columns
plot(density(rates$Violent.Crime.rate), main="Density Plot: Violent Crime Rate", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(rates$Violent.Crime.rate), 2)))  # density plot for 'speed'
polygon(density(rates$Violent.Crime.rate), col="red")
plot(density(rates$Rape.Rate), main="Density Plot: Rape Rate", ylab="Frequency", sub=paste("Skewness:", round(e1071::skewness(rates$Rape.Rate), 2)))  # density plot for 'dist'
polygon(density(rates$Rape.Rate), col="red")
# Correlation against time and population
cor(rates$Violent.Crime.rate, rates$Year)
cor(rates$Violent.Crime.rate, rates$Population)
cor(rates$Rape.Rate, rates$Year)
cor(rates$Rape.Rate, rates$Population)
#Model
vio.lm.fit <- lm(Violent.Crime.rate ~., data=rates)
summary(vio.lm.fit)
#Model
vio.lm.fit <- lm(Violent.Crime.rate ~., data=rates)
summary(vio.lm.fit)
rape.lm.fit <- lm(Rape.Rate ~ ., data=rates)
summary(rape.lm.fit)
# Model assessment
model <- vio.lm.fit
modelSummary <- summary(model)  # capture model summary as an object
modelCoeffs <- modelSummary$coefficients  # model coefficients
beta.estimate <- modelCoeffs["Rape.Rate", "Estimate"]  # get beta estimate for speed
std.error <- modelCoeffs["Rape.Rate", "Std. Error"]  # get std.error for speed
t_value <- beta.estimate/std.error  # calc t statistic
p_value <- 2*pt(-abs(t_value), df=nrow(rates)-ncol(rates))  # calc p Value
f_statistic <- model$fstatistic[1]  # fstatistic
f <- summary(model)$fstatistic  # parameters for model p-value calc
model_p <- pf(f[1], f[2], f[3], lower=FALSE)
t_value # larger t value is better
p_value # low is better
f_statistic
model_p
AIC(model)
BIC(model)
# Prediction models
set.seed(100)
trainingRowIndex <- sample(1:nrow(rates), 0.8*nrow(rates))
train <- rates[trainingRowIndex, ]
test  <- rates[-trainingRowIndex, ]
vio.mod <- lm(Violent.Crime.rate ~., train)
vio.pred <- predict(vio.mod, test)
summary(vio.mod)
AIC(vio.mod)
actuals_preds <- data.frame(cbind(actuals=test$Violent.Crime.rate, predicteds=vio.pred))
correlation_accuracy <- cor(actuals_preds)  # 82.7%
head(actuals_preds)
actuals_preds
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))
min_max_accuracy
rape.mod <- lm(Rape.Rate ~., train)
rape.pred <- predict(rape.mod, test)
summary(rape.mod)
actuals_preds <- data.frame(cbind(actuals=test$Rape.Rate, predicteds=rape.pred))
correlation_accuracy <- cor(actuals_preds)  # 82.7%
head(actuals_preds)
min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max))
min_max_accuracy
# => 92.11%, min_max accuracy
mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
mape # 7.90%
library(tidyverse)
df <- read.csv("crimes_state_time.csv")
df<-df[,-c(7,17)]
rescale <- function(x) (x-min(x))/(max(x) - min(x)) * 100
df[,c(3:21)] <- sapply(df[,c(3:21)], rescale)
rate<-c(1,2,3,13:21)
total<-c(1:12)
rates_df <- df[,rate]
total_df <- df[,total]
all <- c(3:12)
library(BBmisc)
fips <- read.csv("us-state-ansi-fips.csv")
names(fips)[names(fips) == "stname"] <- "State"
rates_df <- left_join(rates_df, fips, by = "State")
total_df <- left_join(total_df, fips, by = "State")
rates2010 <- subset(rates_df, Year == 2010)
names(rates2010)[names(rates2010) == "State"] <- "state"
names(rates_df)[names(rates_df) == "State"] <- "state"
names(total_df)[names(total_df) == "State"] <- "state"
##########
library(gtrendsR)
library(usmap)
orange <- "#0C95BC"
plot_usmap(data = rates2010, values = "Population",  color = orange, labels=FALSE) +
scale_fill_continuous( low = "white", high = orange,
name = "Popularity", label = scales::comma
) +
theme(legend.position = "right") +
theme(panel.background = element_rect(colour = "black")) +
labs(title = "Population in 2010", caption = "Source: FBI UCR")
plot_usmap(data = rates2010, values = "Population", include =  c(.south_atlantic, .mid_atlantic, .new_england ), color = orange, labels=TRUE) +
scale_fill_continuous( low = "white", high = orange,
name = "Popularity", label = scales::comma
) +
theme(legend.position = "right") +
theme(panel.background = element_rect(colour = "black")) +
labs(title = "US East Coast Population", caption = "Source: FBI UCR")
#################
summary(rates_df$Year)
x <- "2014violent.jpg"
y <- 2014
z <- "Violent Crime Total in 2014"
#jpeg(x, width = 568, height = 376)
plot_usmap(data = subset(total_df, Year == y), values = "Violent.crime.total",  color = orange, labels=FALSE) +
scale_fill_continuous( low = "white", high = orange,
name = "Violent Crime", label = scales::comma
) +
theme(legend.position = "right") +
theme(panel.background = element_rect(colour = "black")) +
labs(title = z, caption = "Source: FBI UCR")
#dev.off()
############
library(plyr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(plotly)
library(RColorBrewer)
library(choroplethrMaps)
library(choroplethr)
library(tm)
library(wordcloud)
library(RColorBrewer)
by_state <- rates_df  %>% filter(Year == 2014) %>% group_by(state) %>% select(state, Year, Violent.Crime.rate) %>%
arrange(desc(Violent.Crime.rate))
head(by_state, 10)
tail(by_state, 10)
ggplot(head(by_state, 10), aes(reorder(state, -Violent.Crime.rate), Violent.Crime.rate, fill = Violent.Crime.rate)) +
geom_bar(stat = "identity") + xlab("State") + ylab("Violent Crime Total in 2014") +
theme(axis.text.x = element_text(angle = 90, size = 10, vjust = 0.4, face = "bold"),
plot.title = element_text(size = 20, face = "bold", vjust = 2),
axis.title.x = element_text(face = "bold", size = 15, vjust = -0.35),
axis.title.y = element_text(face = "bold", vjust = 0.35, size = 15)) +
theme(legend.position = "none" )
ggplot(head(by_state, 10), aes(reorder(state, -Violent.Crime.rate), Violent.Crime.rate, fill = Violent.Crime.rate)) +
geom_bar(stat = "identity") + xlab("State") + ylab("Violent Crime Rate in 2014") +
theme(axis.text.x = element_text(angle = 90, size = 10, vjust = 0.4, face = "bold"),
plot.title = element_text(size = 20, face = "bold", vjust = 2),
axis.title.x = element_text(face = "bold", size = 15, vjust = -0.35),
axis.title.y = element_text(face = "bold", vjust = 0.35, size = 15)) +
theme(legend.position = "none" )
ggplot(tail(by_state, 10), aes(reorder(state, -Violent.Crime.rate), Violent.Crime.rate, fill = Violent.Crime.rate)) +
geom_bar(stat = "identity") + xlab("State") + ylab("Violent Crime Rate in 2014") +
theme(axis.text.x = element_text(angle = 90, size = 10, vjust = 0.4, face = "bold"),
plot.title = element_text(size = 20, face = "bold", vjust = 2),
axis.title.x = element_text(face = "bold", size = 15, vjust = -0.35),
axis.title.y = element_text(face = "bold", vjust = 0.35, size = 15)) +
theme(legend.position = "none" )
ggplot(head(by_state, 10), aes(reorder(state, -Violent.Crime.rate), Violent.Crime.rate, fill = Violent.Crime.rate)) +
geom_bar(stat = "identity") + xlab("State") + ylab("Violent Crime Rate in 2014") +
theme(axis.text.x = element_text(angle = 90, size = 10, vjust = 0.4, face = "bold"),
plot.title = element_text(size = 20, face = "bold", vjust = 2),
axis.title.x = element_text(face = "bold", size = 15, vjust = -0.35),
axis.title.y = element_text(face = "bold", vjust = 0.35, size = 15)) +
theme(legend.position = "none" )
ggplot(tail(by_state, 10), aes(reorder(state, -Violent.Crime.rate), Violent.Crime.rate, fill = Violent.Crime.rate)) +
geom_bar(stat = "identity") + xlab("State") + ylab("Violent Crime Rate in 2014") +
theme(axis.text.x = element_text(angle = 90, size = 10, vjust = 0.4, face = "bold"),
plot.title = element_text(size = 20, face = "bold", vjust = 2),
axis.title.x = element_text(face = "bold", size = 15, vjust = -0.35),
axis.title.y = element_text(face = "bold", vjust = 0.35, size = 15)) +
theme(legend.position = "none" )
top.states <- head(rates_df  %>% filter(Year == 1997) %>% group_by(state) %>% select(state, Year, Violent.Crime.rate) %>%
arrange(desc(Violent.Crime.rate)),10)
i <- 1998
while (i < 2015) {
top.states <- rbind(top.states, head(rates_df  %>% filter(Year == i) %>% group_by(state) %>% select(state, Year, Violent.Crime.rate) %>%
arrange(desc(Violent.Crime.rate)),10))
i = i+1
}
counts <- table(top.states$state)
counts <- as.data.frame(counts)
counts <- counts[counts$Freq != 0,]
ggplot(counts, aes(Var1, Freq, fill = Var1)) +
geom_bar(stat = "identity") + xlab("State") + ylab("# Times Appeared in Top 10 Violent Crime Rate") +
theme(axis.text.x = element_text(angle = 90, size = 10, vjust = 0.4, face = "bold"),
plot.title = element_text(size = 20, face = "bold", vjust = 2),
axis.title.x = element_text(face = "bold", size = 15, vjust = -0.35),
axis.title.y = element_text(face = "bold", vjust = 0.35, size = 15)) +
theme(legend.position = "none" )
